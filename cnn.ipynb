{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "812251ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, re, json\n",
    "from glob import glob\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# XAI\n",
    "from captum.attr import IntegratedGradients, LayerGradCam\n",
    "\n",
    "# Optional resampling utilities\n",
    "from nilearn.image import resample_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77512b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Config\n",
    "# --------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Root directory containing all subjects' first‑level outputs\n",
    "    beta_root: str = \"/local/anpa/ds003242-1.0.0/derivatives/firstlevel_separate_runs\"\n",
    "\n",
    "    # Which files to use (glob relative to beta_root). Default: effect‑size maps.\n",
    "    # Examples: \"**/*_effsize.nii.gz\" or \"**/*_zmap.nii.gz\" or \"**/*_tstat.nii.gz\"\n",
    "    file_glob: str = \"**/*_effsize.nii.gz\"\n",
    "\n",
    "    # Regex for extracting labels from file names\n",
    "    # This captures tokens like 'Food_1', 'Social_3', 'Control_2' and collapses to base class\n",
    "    label_regex: str = r\"_(Food|Social|Control)_(?:[123])_\"\n",
    "\n",
    "    # Extract run id (first token like '0_' or '1_'). Used for LORO CV or metadata only.\n",
    "    run_regex: str = r\"/(\\d+)_\"\n",
    "\n",
    "    # Extract subject id from path (directories named sub-XXXX)\n",
    "    subj_regex: str = r\"/(sub-[^/]+)/\"\n",
    "\n",
    "    # If not None, resample all images to this reference NIfTI (common space).\n",
    "    resample_ref_nii: Optional[str] = None\n",
    "\n",
    "    # Mask: if provided, will be resampled to ref and applied; else auto‑mask = nonzero voxels\n",
    "    mask_path: Optional[str] = None\n",
    "\n",
    "    # Training\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    epochs: int = 12\n",
    "    batch_size: int = 4\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-4\n",
    "    num_workers: int = 4\n",
    "    seed: int = 42\n",
    "\n",
    "    # CV mode: 'loso' (leave‑one‑subject‑out) or 'loro' (leave‑one‑run‑out within a chosen subject)\n",
    "    cv_mode: str = 'loso'\n",
    "\n",
    "    # Output\n",
    "    out_dir: str = \"./beta_cnn_outputs\"\n",
    "\n",
    "cfg = Config()\n",
    "os.makedirs(cfg.out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cbe6b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Index beta maps and build a dataframe\n",
    "# --------------------------\n",
    "\n",
    "def index_beta_maps(cfg: Config) -> pd.DataFrame:\n",
    "    paths = sorted(glob(os.path.join(cfg.beta_root, cfg.file_glob), recursive=True))\n",
    "    if len(paths) == 0:\n",
    "        raise FileNotFoundError(\"No beta maps found. Check cfg.beta_root and cfg.file_glob.\")\n",
    "\n",
    "    rows = []\n",
    "    for p in paths:\n",
    "        m_label = re.search(cfg.label_regex, p)\n",
    "        if not m_label:\n",
    "            continue\n",
    "        label = m_label.group(1)  # 'Food'/'Social'/'Control'\n",
    "        m_run = re.search(cfg.run_regex, p)\n",
    "        run_id = m_run.group(1) \n",
    "        m_sub = re.search(cfg.subj_regex, p)\n",
    "        subj = m_sub.group(1) \n",
    "        condition = 'baseline' if subj.endswith('b') else 'isolation' if subj.endswith('s') else 'fasting'\n",
    "        rows.append({\"path\": p, \"label\": label, \"run\": run_id, \"subject\": subj, 'Condition': condition})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        raise RuntimeError(\"No files matched the label regex; inspect cfg.label_regex and filenames.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4e38f61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>run</th>\n",
       "      <th>subject</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/local/anpa/ds003242-1.0.0/derivatives/firstle...</td>\n",
       "      <td>Control</td>\n",
       "      <td>0</td>\n",
       "      <td>sub-SAXSISO01b</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/local/anpa/ds003242-1.0.0/derivatives/firstle...</td>\n",
       "      <td>Control</td>\n",
       "      <td>0</td>\n",
       "      <td>sub-SAXSISO01b</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/local/anpa/ds003242-1.0.0/derivatives/firstle...</td>\n",
       "      <td>Control</td>\n",
       "      <td>0</td>\n",
       "      <td>sub-SAXSISO01b</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/local/anpa/ds003242-1.0.0/derivatives/firstle...</td>\n",
       "      <td>Food</td>\n",
       "      <td>0</td>\n",
       "      <td>sub-SAXSISO01b</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/local/anpa/ds003242-1.0.0/derivatives/firstle...</td>\n",
       "      <td>Food</td>\n",
       "      <td>0</td>\n",
       "      <td>sub-SAXSISO01b</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5152</th>\n",
       "      <td>/local/anpa/ds003242-1.0.0/derivatives/firstle...</td>\n",
       "      <td>Food</td>\n",
       "      <td>5</td>\n",
       "      <td>sub-SAXSISO42s</td>\n",
       "      <td>isolation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5153</th>\n",
       "      <td>/local/anpa/ds003242-1.0.0/derivatives/firstle...</td>\n",
       "      <td>Food</td>\n",
       "      <td>5</td>\n",
       "      <td>sub-SAXSISO42s</td>\n",
       "      <td>isolation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154</th>\n",
       "      <td>/local/anpa/ds003242-1.0.0/derivatives/firstle...</td>\n",
       "      <td>Social</td>\n",
       "      <td>5</td>\n",
       "      <td>sub-SAXSISO42s</td>\n",
       "      <td>isolation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5155</th>\n",
       "      <td>/local/anpa/ds003242-1.0.0/derivatives/firstle...</td>\n",
       "      <td>Social</td>\n",
       "      <td>5</td>\n",
       "      <td>sub-SAXSISO42s</td>\n",
       "      <td>isolation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5156</th>\n",
       "      <td>/local/anpa/ds003242-1.0.0/derivatives/firstle...</td>\n",
       "      <td>Social</td>\n",
       "      <td>5</td>\n",
       "      <td>sub-SAXSISO42s</td>\n",
       "      <td>isolation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5157 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path    label run  \\\n",
       "0     /local/anpa/ds003242-1.0.0/derivatives/firstle...  Control   0   \n",
       "1     /local/anpa/ds003242-1.0.0/derivatives/firstle...  Control   0   \n",
       "2     /local/anpa/ds003242-1.0.0/derivatives/firstle...  Control   0   \n",
       "3     /local/anpa/ds003242-1.0.0/derivatives/firstle...     Food   0   \n",
       "4     /local/anpa/ds003242-1.0.0/derivatives/firstle...     Food   0   \n",
       "...                                                 ...      ...  ..   \n",
       "5152  /local/anpa/ds003242-1.0.0/derivatives/firstle...     Food   5   \n",
       "5153  /local/anpa/ds003242-1.0.0/derivatives/firstle...     Food   5   \n",
       "5154  /local/anpa/ds003242-1.0.0/derivatives/firstle...   Social   5   \n",
       "5155  /local/anpa/ds003242-1.0.0/derivatives/firstle...   Social   5   \n",
       "5156  /local/anpa/ds003242-1.0.0/derivatives/firstle...   Social   5   \n",
       "\n",
       "             subject  Condition  \n",
       "0     sub-SAXSISO01b   baseline  \n",
       "1     sub-SAXSISO01b   baseline  \n",
       "2     sub-SAXSISO01b   baseline  \n",
       "3     sub-SAXSISO01b   baseline  \n",
       "4     sub-SAXSISO01b   baseline  \n",
       "...              ...        ...  \n",
       "5152  sub-SAXSISO42s  isolation  \n",
       "5153  sub-SAXSISO42s  isolation  \n",
       "5154  sub-SAXSISO42s  isolation  \n",
       "5155  sub-SAXSISO42s  isolation  \n",
       "5156  sub-SAXSISO42s  isolation  \n",
       "\n",
       "[5157 rows x 5 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = index_beta_maps(cfg)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "34e6c1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>Control</th>\n",
       "      <th>Food</th>\n",
       "      <th>Social</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sub-SAXSISO01b</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-SAXSISO01f</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-SAXSISO01s</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-SAXSISO02b</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-SAXSISO02f</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-SAXSISO41f</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-SAXSISO41s</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-SAXSISO42b</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-SAXSISO42f</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-SAXSISO42s</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "label           Control  Food  Social\n",
       "subject                              \n",
       "sub-SAXSISO01b       18    18      18\n",
       "sub-SAXSISO01f       18    18      18\n",
       "sub-SAXSISO01s       18    18      18\n",
       "sub-SAXSISO02b       18    18      18\n",
       "sub-SAXSISO02f       18    18      18\n",
       "...                 ...   ...     ...\n",
       "sub-SAXSISO41f       18    18      18\n",
       "sub-SAXSISO41s       18    18      18\n",
       "sub-SAXSISO42b       18    18      18\n",
       "sub-SAXSISO42f       18    18      18\n",
       "sub-SAXSISO42s       18    18      18\n",
       "\n",
       "[96 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"subject\", \"label\"]).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "01b273b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Mask utilities\n",
    "# --------------------------\n",
    "\n",
    "def load_mask(ref_img: nib.Nifti1Image, mask_path: Optional[str]) -> np.ndarray:\n",
    "    if mask_path is None:\n",
    "        data = ref_img.get_fdata()\n",
    "        if data.ndim == 4:\n",
    "            m = data.mean(axis=-1) != 0\n",
    "        else:\n",
    "            m = data != 0\n",
    "        return m.astype(bool)\n",
    "    else:\n",
    "        mask_img = nib.load(mask_path)\n",
    "        if mask_img.shape != ref_img.shape[:3]:\n",
    "            mask_img = resample_to_img(mask_img, ref_img, interpolation='nearest')\n",
    "        return (mask_img.get_fdata() > 0).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "784354e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Dataset: lazy load + per‑sample normalization\n",
    "# --------------------------\n",
    "class BetaDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, label_to_idx: Dict[str,int], mask: Optional[np.ndarray]=None,\n",
    "                 resample_ref_img: Optional[nib.Nifti1Image]=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.label_to_idx = label_to_idx\n",
    "        self.mask = mask\n",
    "        self.resample_ref_img = resample_ref_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = nib.load(row.path)\n",
    "        if self.resample_ref_img is not None and img.shape != self.resample_ref_img.shape:\n",
    "            img = resample_to_img(img, self.resample_ref_img)\n",
    "        vol = img.get_fdata().astype(np.float32)\n",
    "        # apply mask (auto or provided)\n",
    "        if self.mask is None:\n",
    "            mask = (vol != 0)\n",
    "        else:\n",
    "            mask = self.mask\n",
    "        vol = np.where(mask, vol, 0)\n",
    "        # per‑sample z‑score within mask\n",
    "        m = vol[mask]\n",
    "        mu, sigma = float(m.mean()), float(m.std() + 1e-6)\n",
    "        vol = (vol - mu) / sigma\n",
    "        vol = np.expand_dims(vol, 0)  # (1, D, H, W)\n",
    "        y = self.label_to_idx[row.label]\n",
    "        meta = {\"subject\": row.subject, \"run\": row.run, \"path\": row.path, \"label\": row.label}\n",
    "        return torch.from_numpy(vol).float(), torch.tensor(y).long(), meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6a1984cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 3D‑CNN (tiny)\n",
    "# --------------------------\n",
    "class Tiny3DCNN(nn.Module):\n",
    "    def __init__(self, n_classes: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 8, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(8)\n",
    "        self.conv2 = nn.Conv3d(8, 16, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(16)\n",
    "        self.conv3 = nn.Conv3d(16, 32, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm3d(32)\n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool3d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32, n_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        return self.head(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6eabe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --------------------------\n",
    "# 3D‑CNN (deeper, residual)\n",
    "# --------------------------\n",
    "class BasicBlock3D(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride=1, dropout_p=0.0):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(in_ch, out_ch, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm3d(out_ch)\n",
    "        self.conv2 = nn.Conv3d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm3d(out_ch)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        self.do    = nn.Dropout3d(p=dropout_p) if dropout_p > 0 else nn.Identity()\n",
    "        self.down  = None\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.down = nn.Sequential(\n",
    "                nn.Conv3d(in_ch, out_ch, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm3d(out_ch)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.do(out)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.down is not None:\n",
    "            identity = self.down(identity)\n",
    "        out += identity\n",
    "        return self.relu(out)\n",
    "\n",
    "class Bigger3DResNet(nn.Module):\n",
    "    \"\"\"A compact ResNet‑style 3D CNN: stem → stages [16,32,64,128] → GAP → FC.\n",
    "    Much larger capacity than Tiny3DCNN but still light enough for beta volumes.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes: int, dropout_p: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv3d(1, 16, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        # stages\n",
    "        self.layer1 = nn.Sequential(\n",
    "            BasicBlock3D(16, 16, stride=1, dropout_p=dropout_p),\n",
    "            BasicBlock3D(16, 16, stride=1, dropout_p=dropout_p),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            BasicBlock3D(16, 32, stride=2, dropout_p=dropout_p),\n",
    "            BasicBlock3D(32, 32, stride=1, dropout_p=dropout_p),\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            BasicBlock3D(32, 64, stride=2, dropout_p=dropout_p),\n",
    "            BasicBlock3D(64, 64, stride=1, dropout_p=dropout_p),\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            BasicBlock3D(64, 128, stride=2, dropout_p=dropout_p),\n",
    "            BasicBlock3D(128, 128, stride=1, dropout_p=dropout_p),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool3d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(128, n_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return self.head(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c3ce3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Train / eval helpers\n",
    "# --------------------------\n",
    "\n",
    "def train(model, train_loader, val_loader, device, epochs=12, lr=1e-3, weight_decay=1e-4):\n",
    "    torch.manual_seed(cfg.seed)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    best, best_path = -np.inf, os.path.join(cfg.out_dir, 'best_model.pt')\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train(); tot=0; cor=0; loss_sum=0.0\n",
    "        for xb, yb, _ in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad(); logits = model(xb); loss = crit(logits, yb); loss.backward(); opt.step()\n",
    "            loss_sum += float(loss.item()) * xb.size(0)\n",
    "            cor += (logits.argmax(1) == yb).sum().item(); tot += xb.size(0)\n",
    "        tr_acc, tr_loss = cor/max(tot,1), loss_sum/max(tot,1)\n",
    "\n",
    "        model.eval(); tot=0; cor=0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _ in val_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                logits = model(xb)\n",
    "                cor += (logits.argmax(1) == yb).sum().item(); tot += xb.size(0)\n",
    "        va_acc = cor/max(tot,1)\n",
    "        print(f\"Epoch {ep:02d} | train loss {tr_loss:.4f} acc {tr_acc:.3f} | val acc {va_acc:.3f}\")\n",
    "        if va_acc > best:\n",
    "            best = va_acc; torch.save(model.state_dict(), best_path)\n",
    "    print(f\"Best val acc: {best:.3f}; saved {best_path}\")\n",
    "    return best_path\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device, label_names: List[str]):\n",
    "    model.eval()\n",
    "    ys, ps = [], []\n",
    "    metas = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb, meta in loader:\n",
    "            xb = xb.to(device)\n",
    "            logits = model(xb)\n",
    "            ps.extend(logits.argmax(1).cpu().numpy().tolist())\n",
    "            ys.extend(yb.numpy().tolist())\n",
    "            metas.extend(meta)\n",
    "    cm = confusion_matrix(ys, ps)\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "    print(classification_report(ys, ps, target_names=label_names, digits=3))\n",
    "    return cm, ys, ps, metas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3adaca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# XAI: Integrated Gradients & Layer Grad‑CAM\n",
    "# --------------------------\n",
    "\n",
    "def explain_IG(model, volume_3d: np.ndarray, target_class: int, device: str) -> np.ndarray:\n",
    "    model.eval()\n",
    "    tens = torch.from_numpy(volume_3d[None, None].astype(np.float32)).to(device)\n",
    "    ig = IntegratedGradients(model)\n",
    "    attr = ig.attribute(tens, target=target_class, baselines=torch.zeros_like(tens), n_steps=64)\n",
    "    return attr.detach().cpu().numpy()[0,0]\n",
    "\n",
    "\n",
    "def explain_GradCAM(model, volume_3d: np.ndarray, target_class: int, device: str, layer: nn.Module) -> np.ndarray:\n",
    "    model.eval()\n",
    "    tens = torch.from_numpy(volume_3d[None, None].astype(np.float32)).to(device)\n",
    "    lgc = LayerGradCam(model, layer)\n",
    "    attr = lgc.attribute(tens, target=target_class)\n",
    "    up = F.interpolate(attr, size=volume_3d.shape, mode='trilinear', align_corners=False)\n",
    "    return up.detach().cpu().numpy()[0,0]\n",
    "\n",
    "\n",
    "def save_as_nii(arr: np.ndarray, like_path: str, out_path: str):\n",
    "    ref = nib.load(like_path)\n",
    "    nib.save(nib.Nifti1Image(arr.astype(np.float32), affine=ref.affine, header=ref.header), out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b8c92608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Build splits (LOSO or LORO)\n",
    "# --------------------------\n",
    "\n",
    "def make_splits(df: pd.DataFrame, mode: str='loso', seed: int=42):\n",
    "    if mode == 'loso':\n",
    "        subjects = sorted(df.subject.unique())\n",
    "        # pick the last subject as test (example); loop over subjects for full CV\n",
    "        test_subj = subjects[-1]\n",
    "        tr = df[df.subject != test_subj].reset_index(drop=True)\n",
    "        te = df[df.subject == test_subj].reset_index(drop=True)\n",
    "        # split train into train/val stratified by label\n",
    "        tr_idx = np.arange(len(tr))\n",
    "        tr_idx, va_idx = train_test_split(tr_idx, test_size=0.2, stratify=tr.label, random_state=seed)\n",
    "        return tr.iloc[tr_idx], tr.iloc[va_idx], te, {\"test_subject\": test_subj}\n",
    "    elif mode == 'loro':\n",
    "        # assume single subject; hold out one run id\n",
    "        runs = sorted(df.run.unique())\n",
    "        test_run = runs[-1]\n",
    "        tr = df[df.run != test_run].reset_index(drop=True)\n",
    "        te = df[df.run == test_run].reset_index(drop=True)\n",
    "        tr_idx = np.arange(len(tr))\n",
    "        tr_idx, va_idx = train_test_split(tr_idx, test_size=0.2, stratify=tr.label, random_state=seed)\n",
    "        return tr.iloc[tr_idx], tr.iloc[va_idx], te, {\"test_run\": test_run}\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'loso' or 'loro'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split info: {'test_subject': 'sub-SAXSISO42s'}\n",
      "Train/Val/Test sizes: 4082 1021 54\n",
      "Epoch 01 | train loss 1.1044 acc 0.338 | val acc 0.344\n",
      "Epoch 02 | train loss 1.1023 acc 0.339 | val acc 0.332\n",
      "Epoch 03 | train loss 1.0977 acc 0.361 | val acc 0.356\n",
      "Epoch 04 | train loss 1.0959 acc 0.353 | val acc 0.338\n",
      "Epoch 05 | train loss 1.0967 acc 0.368 | val acc 0.324\n",
      "Epoch 06 | train loss 1.0958 acc 0.351 | val acc 0.331\n",
      "Epoch 07 | train loss 1.0962 acc 0.357 | val acc 0.350\n",
      "Epoch 08 | train loss 1.0934 acc 0.371 | val acc 0.341\n",
      "Epoch 09 | train loss 1.0934 acc 0.368 | val acc 0.341\n",
      "Epoch 10 | train loss 1.0940 acc 0.361 | val acc 0.346\n",
      "Epoch 11 | train loss 1.0922 acc 0.370 | val acc 0.343\n",
      "Epoch 12 | train loss 1.0929 acc 0.373 | val acc 0.339\n",
      "Best val acc: 0.356; saved ./beta_cnn_outputs/best_model.pt\n",
      "Confusion matrix:\n",
      " [[ 9  0  9]\n",
      " [10  0  8]\n",
      " [ 7  0 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Control      0.346     0.500     0.409        18\n",
      "        Food      0.000     0.000     0.000        18\n",
      "      Social      0.393     0.611     0.478        18\n",
      "\n",
      "    accuracy                          0.370        54\n",
      "   macro avg      0.246     0.370     0.296        54\n",
      "weighted avg      0.246     0.370     0.296        54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/anpa/.conda/envs/py39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/local/anpa/.conda/envs/py39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/local/anpa/.conda/envs/py39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Generate and save attributions\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m, ex \u001b[38;5;129;01min\u001b[39;00m examples\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Load the original volume as the model saw it (with mask + zscore)\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     img \u001b[38;5;241m=\u001b[39m nib\u001b[38;5;241m.\u001b[39mload(\u001b[43mex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resample_ref_img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m img\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m resample_ref_img\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m     68\u001b[0m         img \u001b[38;5;241m=\u001b[39m resample_to_img(img, resample_ref_img)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# MAIN\n",
    "# --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(cfg.seed); torch.manual_seed(cfg.seed)\n",
    "\n",
    "    df = index_beta_maps(cfg)\n",
    "\n",
    "    # Create label mapping\n",
    "    labels = sorted(df.label.unique().tolist())\n",
    "    label_to_idx = {c:i for i,c in enumerate(labels)}\n",
    "    idx_to_label = {i:c for c,i in label_to_idx.items()}\n",
    "    with open(os.path.join(cfg.out_dir, \"label_mapping.json\"), \"w\") as f:\n",
    "        json.dump(idx_to_label, f, indent=2)\n",
    "\n",
    "    # Choose reference image for resampling/masking\n",
    "    ref_path = df.path.iloc[0]\n",
    "    ref_img = nib.load(ref_path)\n",
    "    mask = load_mask(ref_img, cfg.mask_path)\n",
    "    resample_ref_img = None\n",
    "    if cfg.resample_ref_nii is not None:\n",
    "        resample_ref_img = nib.load(cfg.resample_ref_nii)\n",
    "        mask = load_mask(resample_ref_img, cfg.mask_path)\n",
    "\n",
    "    # Splits\n",
    "    train_df, val_df, test_df, split_meta = make_splits(df, mode=cfg.cv_mode, seed=cfg.seed)\n",
    "    print(\"Split info:\", split_meta)\n",
    "    print(\"Train/Val/Test sizes:\", len(train_df), len(val_df), len(test_df))\n",
    "\n",
    "    # Datasets\n",
    "    ds_tr = BetaDataset(train_df, label_to_idx, mask=mask, resample_ref_img=resample_ref_img)\n",
    "    ds_va = BetaDataset(val_df,   label_to_idx, mask=mask, resample_ref_img=resample_ref_img)\n",
    "    ds_te = BetaDataset(test_df,  label_to_idx, mask=mask, resample_ref_img=resample_ref_img)\n",
    "\n",
    "    # Loaders\n",
    "    dl_tr = DataLoader(ds_tr, batch_size=cfg.batch_size, shuffle=True,  num_workers=cfg.num_workers)\n",
    "    dl_va = DataLoader(ds_va, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "    dl_te = DataLoader(ds_te, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "\n",
    "    # Model\n",
    "    model = Tiny3DCNN(n_classes=len(labels)).to(cfg.device)\n",
    "\n",
    "    # Train\n",
    "    best_path = train(model, dl_tr, dl_va, cfg.device, epochs=cfg.epochs, lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "    model.load_state_dict(torch.load(best_path, map_location=cfg.device))\n",
    "\n",
    "    # Evaluate\n",
    "    cm, ys, ps, metas = evaluate(model, dl_te, cfg.device, labels)\n",
    "\n",
    "    # --------------\n",
    "    # XAI on a few test samples (one per class if available)\n",
    "    # --------------\n",
    "    os.makedirs(cfg.out_dir, exist_ok=True)\n",
    "    # Collect one example path per predicted class\n",
    "    examples: Dict[str, Dict] = {}\n",
    "    for y, p, meta in zip(ys, ps, metas):\n",
    "        cls = labels[p]\n",
    "        if cls not in examples:\n",
    "            examples[cls] = {\"meta\": meta, \"y\": y, \"p\": p}\n",
    "        if len(examples) == len(labels):\n",
    "            break\n",
    "\n",
    "    # Generate and save attributions\n",
    "    for cls, ex in examples.items():\n",
    "        # Load the original volume as the model saw it (with mask + zscore)\n",
    "        img = nib.load(ex[\"meta\"][\"path\"])\n",
    "        if resample_ref_img is not None and img.shape != resample_ref_img.shape:\n",
    "            img = resample_to_img(img, resample_ref_img)\n",
    "        vol = img.get_fdata().astype(np.float32)\n",
    "        vol = np.where(mask, vol, 0)\n",
    "        m = vol[mask]; vol = (vol - float(m.mean()))/(float(m.std())+1e-6)\n",
    "\n",
    "        target_idx = ex[\"p\"]  # explain the predicted class; change to ex[\"y\"] to explain true class\n",
    "        ig_map = explain_IG(model, vol, target_idx, cfg.device)\n",
    "        gc_map = explain_GradCAM(model, vol, target_idx, cfg.device, layer=model.conv3)\n",
    "\n",
    "        base = os.path.splitext(os.path.basename(ex[\"meta\"][\"path\"]))[0]\n",
    "        ig_path = os.path.join(cfg.out_dir, f\"xai_IG_{cls}_{base}.nii.gz\")\n",
    "        gc_path = os.path.join(cfg.out_dir, f\"xai_GradCAM_{cls}_{base}.nii.gz\")\n",
    "        save_as_nii(ig_map, ex[\"meta\"][\"path\"], ig_path)\n",
    "        save_as_nii(gc_map, ex[\"meta\"][\"path\"], gc_path)\n",
    "        print(f\"Saved XAI maps for class {cls}:\\n  {ig_path}\\n  {gc_path}\")\n",
    "\n",
    "    # Save split metadata for provenance\n",
    "    with open(os.path.join(cfg.out_dir, \"split_meta.json\"), \"w\") as f:\n",
    "        json.dump(split_meta, f, indent=2)\n",
    "\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "85522efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Control': {'meta': 'subject', 'y': 0, 'p': 0},\n",
       " 'Social': {'meta': 'path', 'y': 0, 'p': 2}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed5dcd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
